#version 460 core
#extension GL_GOOGLE_include_directive : enable

#include "./includes.glsl"

layout (local_size_x = BLOCK_SIZE) in;
shared uint localHistogram[RADICES];

// planned 64-wide for Turing
shared m8pq utype_v _data[Wave_Size];
shared blocks_info blocks;
#define key _data[Lane_Idx]
#define bcount blocks.count

#ifndef ENABLE_TURING_INSTRUCTION_SET
initSubgroupIncFunctionTarget(localHistogram[WHERE], countOffset, 1, uint)
#endif

const uint Wc = RADICES/Wave_Count;
const uint BSIZE = min(Wc,Wave_Size);

void main() {
    //const m8pq utype_t Radice_Idx = utype_t(gl_WorkGroupID.y * Wave_Count_RX + Wave_Idx);
    const lowp uint Wr = Wc * Wave_Idx;

    // set prefix sum (planned distribute threads)
    [[flatten]] if (Wave_Idx == 0u) 
        [[unroll]] for (lowp uint rk=0u;rk<RADICES;rk+=Wave_Size_RT) {
        const lowp uint radice = rk + Lane_Idx;
        [[flatten]] if (radice < RADICES) localHistogram[radice+0u] = PrefixSum[gl_WorkGroupID.x * RADICES + radice];
    };
    [[flatten]] if (Local_Idx == 0) blocks = get_blocks_info(push_block.NumKeys), bcount = min(blocks.count, 1048576u);
    LGROUP_BARRIER
    [[flatten]] IFANY (bcount <= 0) return;

    // calculate blocks
    WPTR4 addr = WPTR4(0,1,2,3)*Wave_Size_RT.xxxx + WPTR4(blocks.offset.xxxx) + WPTR4(Lane_Idx.xxxx);
    [[dependency_infinite]] for ( uint wk = 0; wk < bcount; wk++ ) {
        LGROUP_BARRIER
        const bvec4 validAddress = lessThan(addr, blocks.limit.xxxx); IFALL(all(not(validAddress))) break;
        [[flatten]] if (Wave_Idx < 4u) { key[Wave_Idx] = utype_t(BFE(validAddress[Wave_Idx] ? KeyIn[addr[Wave_Idx]] : OutOfRange, (push_block.Shift)*BITS_PER_PASS, BITS_PER_PASS)); };
        LGROUP_BARRIER

#ifdef ENABLE_TURING_INSTRUCTION_SET
        [[flatten]] if (Wave_Idx == 0u) 
#endif
        //[[flatten]] if (w < 4u) 
        [[unroll]] for (lowp uint w=0;w<4;w++) 
        {
#ifdef ENABLE_TURING_INSTRUCTION_SET
            const highp uvec4 blt = subgroupPartitionNV(key[w])&subgroupBallot(validAddress[w]);
            const uint btc = subgroupPartitionedAddNV(1u,blt), btl = subgroupPartitionedExclusiveAddNV(1u,blt), fLn = subgroupBallotFindMSB(blt);
            uint cntl = 0u; [[flatten]] if (fLn == Lane_Idx && validAddress[w]) { cntl = add(localHistogram[uint(key[w])], btc); };
            {
                const uint offset = subgroupShuffle(cntl,fLn) + btl;
                [[flatten]] if (validAddress[w]) { ValueTmp[offset] = ValueIn[addr[w]], KeyTmp[offset] = KeyIn[addr[w]]; };
            };
#else
#ifdef SIMPLER_SORT
            [[flatten]] if (key[w] == Wr && validAddress[w]) {
                const uint offset = countOffset(key[w]);
                ValueTmp[offset] = ValueIn[addr[w]], KeyTmp[offset] = KeyIn[addr[w]];
            };
#else
            bool found = !validAddress[w] || key[w]<Wr || key[w]>=(Wr+Wc);
             for (lowp uint t=0;t<BSIZE;t+=1u) {
                [[flatten]] if (!found && (found = subgroupMin(key[w])==key[w])) {
                    const uint offset = countOffset(key[w]);
                    ValueTmp[offset] = ValueIn[addr[w]], KeyTmp[offset] = KeyIn[addr[w]];
                };
                IFALL (found) { break; };
            };
#endif
#endif
        };
        addr += ( Wave_Size_RT << 2u );
    };
};
