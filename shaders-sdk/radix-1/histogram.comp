#version 460 core
#extension GL_GOOGLE_include_directive : enable

#include "./includes.glsl"

layout (local_size_x = BLOCK_SIZE) in;

shared uint localHistogram[RADICES];

// wide of 128 elements, each element should be in uint16_t, but for compatibility used uint32_t
shared lowp uint _data[Wave_Size];

shared blocks_info blocks;
#define key _data[Lane_Idx]

//initSubgroupIncFunctionTarget(localHistogram[WHERE], countHistogram, 1, uint)

#define bcount blocks.count

void main() {
    const utype_t Radice_Idx = utype_t(gl_WorkGroupID.y * Wave_Count_RX + Wave_Idx);

    // clear histogram of block (planned distribute threads)
    [[unroll]] for (utype_t rk=utype_t(0u);rk<utype_t(RADICES);rk+=utype_t(WRK_SIZE_RT)) {
        const utype_t radice = utype_t(rk) + utype_t(Radice_Idx);
        [[flatten]] if (radice < RADICES) localHistogram[radice+0u] = 0u;
    };
    [[flatten]] if (Local_Idx == 0) blocks = get_blocks_info(push_block.NumKeys), bcount = min(blocks.count, 524288u);
    LGROUP_BARRIER
    [[flatten]] IFANY (bcount <= 0) return;

    // use SIMD lanes for calculate histograms
    WPTR1 addr = WPTR1(0)*Wave_Size_RT.x + WPTR1(blocks.offset.x) + WPTR1(Lane_Idx.x);
    [[dependency_infinite]] for ( uint wk = 0; wk < bcount; wk++ ) {
        //LGROUP_BARRIER

        const bool validAddress = addr < blocks.limit.x; IFALL(!validAddress) break;
        [[flatten]] if (Wave_Idx == 0) { key.x = BFE(validAddress.x ? KeyIn[addr.x] : OutOfRange, (push_block.Shift)*BITS_PER_PASS, BITS_PER_PASS); };
        LGROUP_BARRIER

        // WARP-optimized histogram calculation
        [[unroll]] for (utype_t rk=utype_t(0u);rk<utype_t(RADICES);rk+=utype_t(WRK_SIZE_RT)) {
             const utype_t radice = utype_t(rk) + utype_t(Radice_Idx);
             const bool owned = key.x == radice.x && validAddress;
             [[flatten]] if (owned) {
                const uint btc = subgroupBallotBitCount(subgroupBallot(true)); 
                [[flatten]] if (subgroupElect()) localHistogram[radice+0u] += btc;
             };
             IFALL ( radice >= RADICES || !validAddress ) break;
        }
        addr += ( Wave_Size_RT << 0u );
    }

    // resolve histograms (planned distribute threads) 
    LGROUP_BARRIER

    [[unroll]] for (utype_t rk=utype_t(0u);rk<utype_t(RADICES);rk+=utype_t(WRK_SIZE_RT)) {
         const utype_t radice = utype_t(rk) + utype_t(Radice_Idx);
         [[flatten]] if (radice < utype_t(RADICES)) {
            PrefixSum[RADICES * gl_WorkGroupID.x + radice] = localHistogram[radice+0u];
            Histogram[RADICES * gl_WorkGroupID.x + radice] = localHistogram[radice+0u];
         };
    };
};
